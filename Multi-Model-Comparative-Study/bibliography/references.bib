% CardioEmbed References

% Base Models
@article{qwen3,
  title={Qwen3 Embedding: Advancing Text Embedding and Reranking Through Foundation Models},
  author={Zhang, Yanzhao and Li, Mingxin and Long, Dingkun and Zhang, Xin and Lin, Huan and Yang, Baosong and Xie, Pengjun and Yang, An and Liu, Dayiheng and Lin, Junyang and Huang, Fei and Zhou, Jingren},
  journal={arXiv preprint arXiv:2506.05176},
  year={2025},
  eprint={2506.05176},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/2506.05176}
}

% Medical Embeddings
@article{pubmedbert,
  title={Domain-Specific Language Model Pretraining for Biomedical Natural Language Processing},
  author={Gu, Yu and Tinn, Robert and Cheng, Hao and Lucas, Michael and Usuyama, Naoto and Liu, Xiaodong and Naumann, Tristan and Gao, Jianfeng and Poon, Hoifung},
  journal={ACM Transactions on Computing for Healthcare},
  volume={3},
  number={1},
  pages={1--23},
  year={2021}
}

@article{biobert,
  title={BioBERT: a pre-trained biomedical language representation model for biomedical text mining},
  author={Lee, Jinhyuk and Yoon, Wonjin and Kim, Sungdong and Kim, Donghyeon and Kim, Sunkyu and So, Chan Ho and Kang, Jaewoo},
  journal={Bioinformatics},
  volume={36},
  number={4},
  pages={1234--1240},
  year={2020}
}

@misc{medte,
  title={MedTE: Medical Text Embeddings via Contrastive Learning},
  author={Khodadad, Mohammad},
  howpublished={HuggingFace Model Repository},
  url={https://huggingface.co/MohammadKhodadad/MedTE-cl15-step-8000},
  year={2024}
}

% Benchmarks
@inproceedings{mteb,
  title={MTEB: Massive Text Embedding Benchmark},
  author={Muennighoff, Niklas and Tazi, Nouamane and Magne, Loic and Reimers, Nils},
  booktitle={Proceedings of EACL},
  pages={2014--2037},
  year={2023}
}

% Textbooks (sample entries)
@book{braunwalds,
  title={Braunwald's Heart Disease: A Textbook of Cardiovascular Medicine},
  author={Zipes, Douglas P and Libby, Peter and Bonow, Robert O and Mann, Douglas L and Tomaselli, Gordon F and Braunwald, Eugene},
  edition={11},
  publisher={Elsevier},
  year={2018}
}

@book{esc_imaging,
  title={The ESC Textbook of Cardiovascular Imaging},
  author={Zamorano, Jose Luis and Bax, Jeroen J and Rademakers, Frank and Knuuti, Juhani},
  edition={3},
  publisher={Oxford University Press},
  year={2021}
}

% Contrastive Learning
@article{infonce,
  title={Representation learning with contrastive predictive coding},
  author={van den Oord, Aaron and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

% OCR
@article{deepseek_ocr,
  title={DeepSeek-OCR: Contexts Optical Compression},
  author={Wei, Haoran and Sun, Yaofeng and Li, Yukun},
  journal={arXiv preprint arXiv:2510.18234},
  year={2025},
  eprint={2510.18234},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/2510.18234}
}

% ML Frameworks
@inproceedings{wolf2020huggingface,
  title={Transformers: State-of-the-Art Natural Language Processing},
  author={Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, Remi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and von Platen, Patrick and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Le Scao, Teven and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  pages={38--45},
  year={2020}
}

% ========================================
% CLINICAL & MEDICAL EMBEDDINGS - KEY COMPARISONS
% ========================================

@article{clinical_modernbert,
  title={Clinical ModernBERT: An efficient and long context encoder for biomedical text},
  author={Lee, Simon A. and Wu, Anthony and Chiang, Jeffrey N.},
  journal={arXiv preprint arXiv:2504.03964},
  year={2025},
  eprint={2504.03964},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/2504.03964}
}

@article{medeir,
  title={MedEIR: A Specialized Medical Embedding Model for Enhanced Information Retrieval},
  author={Selvadurai, Anand and others},
  journal={arXiv preprint arXiv:2505.13482},
  year={2025},
  eprint={2505.13482},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/2505.13482}
}

@article{domain_specification,
  title={Towards Domain Specification of Embedding Models in Medicine},
  author={Khodadad, Mohammad and Kasmaee, Ali Shiraee and Astaraki, Mahdi and Mahyar, Hamidreza},
  journal={arXiv preprint arXiv:2507.19407},
  year={2025},
  eprint={2507.19407},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/2507.19407}
}

% ========================================
% CARDIOLOGY NLP
% ========================================

@article{cardiology_nlp_review,
  title={Natural Language Processing for Cardiology: A Narrative Review},
  author={Yang, Kailai and Leng, Yan and Zhang, Xin and Zhang, Tianlin and Thompson, Paul and Keavney, Bernard and Tomaszewski, Maciej and Ananiadou, Sophia},
  journal={arXiv preprint arXiv:2510.16708},
  year={2025},
  eprint={2510.16708},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/2510.16708}
}

% ========================================
% FOUNDATIONAL MEDICAL EMBEDDINGS
% ========================================

@article{cui2vec,
  title={Clinical Concept Embeddings Learned from Massive Sources of Multimodal Medical Data},
  author={Beam, Andrew L. and Kompa, Benjamin and Schmaltz, Allen and Fried, Inbar and Weber, Griffin and Palmer, Nathan and Shi, Xu and Cai, Tianxi and Kohane, Isaac S.},
  journal={Pacific Symposium on Biocomputing},
  volume={25},
  pages={295--306},
  year={2020},
  doi={10.1142/9789811215636_0027}
}

@inproceedings{biosentvec,
  title={BioSentVec: creating sentence embeddings for biomedical texts},
  author={Chen, Qingyu and Peng, Yifan and Lu, Zhiyong},
  booktitle={2019 IEEE International Conference on Healthcare Informatics (ICHI)},
  pages={1--5},
  year={2019},
  doi={10.1109/ICHI.2019.8904728}
}

@article{biowordvec,
  title={BioWordVec, improving biomedical word embeddings with subword information and MeSH},
  author={Zhang, Yijia and Chen, Qingyu and Yang, Zhihao and Lin, Hongfei and Lu, Zhiyong},
  journal={Scientific Data},
  volume={6},
  number={1},
  pages={52},
  year={2019},
  doi={10.1038/s41597-019-0055-0}
}

% ========================================
% EPIDEMIOLOGY & HEALTH ECONOMICS
% ========================================

@article{tsao_heart_disease_2024,
  title={2024 Heart Disease and Stroke Statistics: A Report of US and Global Data From the American Heart Association},
  author={Tsao, Connie W. and Aday, Aaron W. and Almarzooq, Zaid I. and Anderson, Cheryl A. M. and Arora, Pankaj and Avery, Christy L. and others},
  journal={Circulation},
  volume={149},
  number={8},
  pages={e347--e913},
  year={2024},
  doi={10.1161/CIR.0000000000001209}
}

@article{kazi_economic_burden_2024,
  title={Forecasting the Economic Burden of Cardiovascular Disease and Stroke in the United States Through 2050: A Presidential Advisory From the American Heart Association},
  author={Kazi, Dhruv S. and Wadhera, Rishi K. and Shen, Cynthia and Maron, David J. and Kaltenbach, Lisa A. and Yeh, Robert W. and others},
  journal={Circulation},
  volume={150},
  number={2},
  pages={e89--e115},
  year={2024},
  doi={10.1161/CIR.0000000000001258}
}

% Add more references as needed

% ========================================
% FOUNDATIONAL SENTENCE EMBEDDINGS & CONTRASTIVE LEARNING
% ========================================

@inproceedings{sentencebert2019,
  title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  author={Reimers, Nils and Gurevych, Iryna},
  booktitle={EMNLP 2019},
  year={2019},
  eprint={1908.10084},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/1908.10084}
}

@inproceedings{simcse2021,
  title={SimCSE: Simple Contrastive Learning of Sentence Embeddings},
  author={Gao, Tianyu and Yao, Xingcheng and Chen, Danqi},
  booktitle={EMNLP 2021},
  year={2021},
  eprint={2104.08821},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/2104.08821}
}

@article{lora2021,
  title={LoRA: Low-Rank Adaptation of Large Language Models},
  author={Hu, Edward J and others},
  journal={arXiv preprint arXiv:2106.09685},
  year={2021},
  eprint={2106.09685},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/2106.09685}
}

% ========================================
% SCIENTIFIC/CLINICAL DOMAIN MODELS
% ========================================

@inproceedings{scibert2019,
  title={SciBERT: A Pretrained Language Model for Scientific Text},
  author={Beltagy, Iz and Lo, Kyle and Cohan, Arman},
  booktitle={EMNLP 2019},
  year={2019},
  eprint={1903.10676},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/1903.10676}
}

@article{clinicalbert2019,
  title={Publicly Available Clinical BERT Embeddings},
  author={Alsentzer, Emily and others},
  journal={arXiv preprint arXiv:1904.05342},
  year={2019},
  eprint={1904.05342},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/1904.05342}
}

% ========================================
% IR BENCHMARKS & RETRIEVAL METHODS
% ========================================

@inproceedings{beir2021,
  title={BEIR: A Heterogeneous Benchmark for Zero-shot Evaluation of Information Retrieval Models},
  author={Thakur, Nandan and others},
  booktitle={NeurIPS Datasets and Benchmarks},
  year={2021},
  eprint={2104.08663},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/2104.08663}
}

@article{contriever2021,
  title={Unsupervised Dense Information Retrieval with Contrastive Learning},
  author={Izacard, Gautier and others},
  journal={arXiv preprint arXiv:2112.09118},
  year={2021},
  eprint={2112.09118},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/2112.09118}
}

% ========================================
% EVALUATION DATASETS (MTEB TASKS)
% ========================================

@inproceedings{biosses2017,
  title={BIOSSES: A Semantic Sentence Similarity Corpus for the Biomedical Domain},
  author={Sogancioglu, Gizem and Ozyurt, Ibrahim and Ozturk, Arzucan},
  booktitle={BioNLP 2017 Workshop},
  year={2017}
}

@inproceedings{scifact2020,
  title={Fact or Fiction: Verifying Scientific Claims},
  author={Wadden, David and others},
  booktitle={EMNLP 2020},
  year={2020},
  eprint={2004.14974},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/2004.14974}
}

@inproceedings{nfcorpus2016,
  title={A Full-Text Learning to Rank Dataset for Medical Information Retrieval},
  author={Boteva, Veronika and others},
  booktitle={Proceedings of the 2016 Conference on Information and Knowledge Management},
  year={2016}
}
